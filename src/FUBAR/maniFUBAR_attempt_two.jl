# ----------------------------------------------------------------------------
# â€” abstract "Prior" interface + dispatchers
# ----------------------------------------------------------------------------
abstract type Prior end

# â€” Forward declaration of the problem type
struct HierarchicalRMALAProblem{PÎ¼<:Prior, PÎ£<:Prior}
    grids
    prior_mu::PÎ¼
    prior_sigma::PÎ£
end

# â€” Normal prior on each Î¼áµ¢ ~ ð’©(0, Î£)
struct NormalPrior <: Prior end

function logprior(::NormalPrior, Î¼s::Vector{Vector{T}}, Î£::AbstractMatrix{T}) where T
    lp = 1/2 * logdet(Î£)
    for Î¼ in Î¼s
        lp -= 1/2 * dot(Î¼, Î£ \ Î¼)
    end
    return lp
end

function grad_logprior(::NormalPrior, Î¼s::Vector{Vector{T}}, Î£::AbstractMatrix{T}) where T
    return [ -(Î£ \ Î¼) for Î¼ in Î¼s ]
end

function euclid_grad_logprior(::NormalPrior, Î¼s::Vector{Vector{T}}, Î£::AbstractMatrix{T}) where T
    N = length(Î¼s)
    S = zeros(eltype(Î£), size(Î£))
    for Î¼ in Î¼s
        S .+= Î¼ * Î¼'
    end
    t1 = -N/2 * inv(Î£)
    t2 = +1/2 * inv(Î£) * S * inv(Î£)
    return t1 .+ t2
end

# â€” Wishart prior Î£ ~ W(df, V0)
struct WishartPrior{T} <: Prior
    df::Int
    V0::Matrix{T}
end

function logprior(p::WishartPrior, Î£::AbstractMatrix{T}) where T
    Î½, V0 = p.df, p.V0; K = size(Î£,1)
    return ((Î½ - K - 1)/2)*logdet(Î£) - 1/2*tr(inv(V0)*Î£)
end

function grad_logprior(p::WishartPrior, Î£::AbstractMatrix{T}) where T
    Î½, V0 = p.df, p.V0; K = size(Î£,1)
    return ((Î½ - K - 1)/2)*inv(Î£) .- 1/2*inv(V0)
end

# â€” Riemannianâ€Gaussian prior on SPD: p(Î£) âˆ exp(âˆ’d_RÂ²(Î£,M)/(2ÏƒÂ²))
struct RiemannianGaussianPrior{T} <: Prior
    M::Matrix{T}
    Ïƒ2::T
end

function logprior(p::RiemannianGaussianPrior, Î£::AbstractMatrix{T}) where T
    S  = sqrt(p.M); iS = inv(S)
    Î”  = log(iS * Î£ * iS)
    d2 = tr(Î” * Î”)
    return -d2/(2*p.Ïƒ2)
end

function grad_logprior(p::RiemannianGaussianPrior, Î£::AbstractMatrix{T}) where T
    S  = sqrt(p.M); iS = inv(S)
    Î”  = log(iS * Î£ * iS)
    return -1/p.Ïƒ2 * (iS * Î” * iS)
end

# ----------------------------------------------------------------------------
# â€” likelihood
# ----------------------------------------------------------------------------
function loglikelihood(p::HierarchicalRMALAProblem, Î¼s)
    ll = 0.0
    for (i, Î¼) in enumerate(Î¼s)
        L = p.grids[i].cond_lik_matrix      # KÃ—N
        # log-softmax â†’ probabilities v sum to 1
        log_soft = Î¼ .- logsumexp(Î¼)
        v        = exp.(log_soft)
        M        = v' * L                  # 1Ã—N row vector
        ll      += sum(log.(M))            # sum_j log M_j
    end
    return ll
end

# ----------------------------------------------------------------------------
# â€” posterior + grads
# ----------------------------------------------------------------------------
function log_posterior(p::HierarchicalRMALAProblem, Î¼s, Î£)
    return loglikelihood(p, Î¼s) +
           logprior(p.prior_mu, Î¼s, Î£) +
           logprior(p.prior_sigma, Î£)
end

function grad_log_post_mu(p::HierarchicalRMALAProblem, Î¼s, Î£)
    gs = [ zeros(length(Î¼)) for Î¼ in Î¼s ]
    for (i, Î¼) in enumerate(Î¼s)
        L = p.grids[i].cond_lik_matrix
        v = exp.(Î¼ .- logsumexp(Î¼)); v ./= sum(v)
        M = v' * L
        w = vec(1.0 ./ M)
        grad_v = L * w
        Î± = dot(v, grad_v)
        gs[i] = v .* (grad_v .- Î±)
    end
    gÎ¼_prior = grad_logprior(p.prior_mu, Î¼s, Î£)
    return [g + gp for (g, gp) in zip(gs, gÎ¼_prior)]
end

function euclid_grad_Sigma(p::HierarchicalRMALAProblem, Î¼s, Î£)
    return euclid_grad_logprior(p.prior_mu, Î¼s, Î£) .+
           grad_logprior(p.prior_sigma, Î£)
end

riemannian_grad_Sigma(p, Î¼s, Î£) = Î£ * euclid_grad_Sigma(p, Î¼s, Î£) * Î£

# ----------------------------------------------------------------------------
# â€” manifold ops
# ----------------------------------------------------------------------------
exp_map_Sigma(Î£, V) = begin
    S  = sqrt(Î£); iS = inv(S)
    return S * exp(iS * V * iS) * S
end

log_map_Sigma(Î£, T) = begin
    S  = sqrt(Î£); iS = inv(S)
    return S * log(iS * T * iS) * S
end

metric_inner_Sigma(Î£, U, V) = tr(inv(Î£)*U*inv(Î£)*V)

function rand_tangent_Sigma(Î£, Ï„)
    K = size(Î£,1)
    W = randn(K,K); symW = (W + W')/âˆš2; S = sqrt(Î£)
    return âˆšÏ„ * (S * symW * S)
end

log_q_mu(Î¼â‚€, Î¼â‚, gâ‚€, Ï„) = begin Î” = Î¼â‚ .- Î¼â‚€ .- (Ï„/2)*gâ‚€; -dot(Î”,Î”)/(2Ï„) end
log_q_Sigma(Î£â‚€, Î£â‚, gâ‚€, Ï„) = begin
    V = log_map_Sigma(Î£â‚€, Î£â‚); Î” = V .- (Ï„/2)*gâ‚€
    -metric_inner_Sigma(Î£â‚€, Î”, Î”)/(2Ï„)
end

# ----------------------------------------------------------------------------
# â€” RMALA iteration with separate taus
# ----------------------------------------------------------------------------
function rmala_step(p::HierarchicalRMALAProblem, Î¼s, Î£, Ï„_mu::Float64, Ï„_sigma::Float64)
    # Compute gradients
    gÎ¼  = grad_log_post_mu(p, Î¼s, Î£)
    gÎ£  = riemannian_grad_Sigma(p, Î¼s, Î£)

    # Propose new mu with its own step size
    Î¼s_new = [ Î¼ .+ (Ï„_mu/2)*g .+ sqrt(Ï„_mu)*randn(length(Î¼)) for (Î¼,g) in zip(Î¼s, gÎ¼) ]

    # Propose new Sigma with its own step size
    Î¶Î£    = rand_tangent_Sigma(Î£, Ï„_sigma)
    Î£_new = exp_map_Sigma(Î£, (Ï„_sigma/2)*gÎ£ .+ Î¶Î£)

    # Compute log-posterior at old and new
    lp0   = log_posterior(p, Î¼s, Î£)
    lp1   = log_posterior(p, Î¼s_new, Î£_new)

    # Forward proposal densities
    lqf   = sum(log_q_mu(Î¼, Î¼p, g, Ï„_mu) for (Î¼,Î¼p,g) in zip(Î¼s, Î¼s_new, gÎ¼)) +
             log_q_Sigma(Î£, Î£_new, gÎ£, Ï„_sigma)

    # Reverse proposal densities
    gÎ¼_new = grad_log_post_mu(p, Î¼s_new, Î£_new)
    gÎ£_new = riemannian_grad_Sigma(p, Î¼s_new, Î£_new)
    lqr   = sum(log_q_mu(Î¼p, Î¼, gp, Ï„_mu) for (Î¼,Î¼p,gp) in zip(Î¼s, Î¼s_new, gÎ¼_new)) +
             log_q_Sigma(Î£_new, Î£, gÎ£_new, Ï„_sigma)

    # Accept/reject
    logÎ± = lp1 - lp0 + (lqr - lqf)
    if log(rand()) < logÎ±
        return Î¼s_new, Î£_new, true
    else
        return Î¼s, Î£, false
    end
end

# ----------------------------------------------------------------------------
# â€” full sampler (separate returns)
# ----------------------------------------------------------------------------
function rmala_sampler(p::HierarchicalRMALAProblem,
                       Î¼s0::Vector{Vector{Float64}},
                       Î£0::Matrix{Float64};
                       Ï„_mu::Float64=1e-4,
                       Ï„_sigma::Float64=1e-4,
                       num_samples::Int=1000,
                       burnin::Int=0)
    Î¼s, Î£ = deepcopy(Î¼s0), deepcopy(Î£0)
    mus_samples   = Vector{Vector{Vector{Float64}}}()
    sigma_samples = Vector{Matrix{Float64}}()
    logpost_samples = Vector{Float64}()
    acc = 0
    total_iter = 0
    current_logpost = log_posterior(p, Î¼s, Î£)

    while length(mus_samples) < num_samples
        total_iter += 1
        Î¼s_new, Î£_new, accepted = rmala_step(p, Î¼s, Î£, Ï„_mu, Ï„_sigma)
        if accepted
            acc += 1; Î¼s, Î£ = Î¼s_new, Î£_new
            current_logpost = log_posterior(p, Î¼s, Î£)
            if total_iter > burnin
                push!(mus_samples, deepcopy(Î¼s))
                push!(sigma_samples, deepcopy(Î£))
                push!(logpost_samples, current_logpost)
            end
        end
        if total_iter % 100 == 0
            @info "Iter $(total_iter): Acceptance rate = $(acc/total_iter), Collected $(length(mus_samples))/$(num_samples) samples"
        end
    end
    @info "Final acceptance rate = $(acc/total_iter), Total iterations = $(total_iter)"
    return mus_samples, sigma_samples, logpost_samples
end
